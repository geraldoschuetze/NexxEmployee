import os
import uuid
import json
import re
import streamlit as st
from dotenv import load_dotenv
from tinydb import TinyDB, Query
from PyPDF2 import PdfReader
from openai import OpenAI

# === Carrega vari√°veis de ambiente ===
dotenv_path = os.path.join(os.path.dirname(__file__), ".env")
load_dotenv(dotenv_path)
api_key = os.getenv("OPENAI_API_KEY", "").strip()
if not api_key:
    st.error("Chave OPENAI_API_KEY n√£o encontrada. Verifique .env sem espa√ßos extras nem aspas.")
    st.stop()
client = OpenAI(api_key=api_key)

# === Templates de descri√ß√£o de vaga ===
activities = """
Participar da defini√ß√£o das tecnologias utilizadas no desenvolvimento dos sistemas
Codificar sistemas e aplica√ß√µes de acordo com padr√µes e metodologias estabelecidas
Estimar prazos para realiza√ß√£o das tarefas com base em documentos de requisitos
Desenvolver sistemas aplicando as tecnologias definidas pelo time
Comentar e documentar o c√≥digo desenvolvido
Criar e aplicar testes unit√°rios
Realizar manuten√ß√µes corretivas em sistemas e aplica√ß√µes (corre√ß√£o de bugs)
"""
prerequisites = """
Conhecimento em Python e Java
Experi√™ncia com frameworks como Django
Familiaridade com Docker, Git e bancos de dados Postgres
Conhecimento sobre metodologias √°geis, especialmente Scrum
Disponibilidade para trabalho presencial em Florian√≥polis, SC
"""
differentials = """
Conhecimento em Flutter
Experi√™ncia com Django Rest Framework ou Flask
Viv√™ncia com pipelines de CI/CD
Familiaridade com arquitetura em nuvem (AWS API Gateway, Lambda Functions)
Experi√™ncia com microservi√ßos, RabbitMQ, Event Source e bancos NoSQL como MongoDB
"""

# === Caching de fun√ß√µes de IA ===
@st.cache_data(show_spinner="Gerando resumo de curr√≠culo...")
def resume_cv(cv_text: str) -> str:
    prompt = f"""
**Solicita√ß√£o de Resumo de Curr√≠culo em Markdown:**

# Curr√≠culo do candidato para resumir:

{cv_text}

Por favor, gere um resumo do curr√≠culo fornecido, formatado em Markdown, seguindo rigorosamente o modelo abaixo. **N√£o adicione se√ß√µes extras, tabelas ou qualquer outro tipo de formata√ß√£o diferente da especificada.** Preencha cada se√ß√£o com as informa√ß√µes relevantes, garantindo que o resumo seja preciso e focado.

**Formato de Output Esperado:**
```markdown
## Nome Completo
nome_completo aqui

## Experi√™ncia
experiencia aqui

## Habilidades
habilidades aqui

## Educa√ß√£o
educacao aqui

## Idiomas
idiomas aqui
```
"""
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role":"system","content":"Voc√™ √© um assistente que resume curr√≠culos em Markdown."},
            {"role":"user","content":prompt}
        ]
    ).choices[0].message.content
    parts = resp.split("```markdown")
    return parts[1].strip() if len(parts) > 1 else resp.strip()

@st.cache_data(show_spinner="Gerando opini√£o cr√≠tica...")
def generate_opinion(cv_text: str, job_desc: str) -> str:
    prompt = f"""
Por favor, analise o curr√≠culo fornecido em rela√ß√£o √† descri√ß√£o da vaga aplicada e crie uma opini√£o ultra cr√≠tica e detalhada. A sua an√°lise deve incluir os seguintes pontos:

1. **Pontos de Alinhamento**: aspectos do curr√≠culo que correspondem aos requisitos.
2. **Pontos de Desalinhamento**: onde o candidato n√£o atende √† vaga.
3. **Pontos de Aten√ß√£o**: lacunas, trocas frequentes, etc.

**Curr√≠culo Original:**
{cv_text}

**Descri√ß√£o da Vaga:**
{job_desc}

Formate a resposta de forma profissional, com t√≠tulos em destaque.
"""
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role":"system","content":"Voc√™ √© o recrutador chefe gerando opini√£o cr√≠tica."},
            {"role":"user","content":prompt}
        ]
    ).choices[0].message.content
    return resp.strip()

# === Helper para stringify ===
def stringify_cell(x):
    if isinstance(x, (list, tuple)):
        return ", ".join(str(i) for i in x)
    if isinstance(x, dict):
        return json.dumps(x)
    return str(x) if x is not None else ""

# === Classe de Banco de Dados ===
class AnalyzeDatabase(TinyDB):
    def __init__(self, file_path='db.json'):
        super().__init__(file_path)
        self.jobs     = self.table('jobs')
        self.resums   = self.table('resums')
        self.analysis = self.table('analysis')
        self.files    = self.table('files')
    def get_job_by_name(self, name):
        q=Query();r=self.jobs.search(q.name==name);return r[0] if r else None
    def get_resum_by_id(self, id):
        q=Query();r=self.resums.search(q.id==id);return r[0] if r else None
    def get_analysis_by_job_id(self, job_id):
        q=Query();return self.analysis.search(q.job_id==job_id)
    def get_resums_by_job_id(self, job_id):
        q=Query();return self.resums.search(q.job_id==job_id)
    def delete_all_resums_by_job_id(self, job_id):
        q=Query();self.resums.remove(q.job_id==job_id)
    def delete_all_analysis_by_job_id(self, job_id):
        q=Query();self.analysis.remove(q.job_id==job_id)
    def delete_all_files_by_job_id(self, job_id):
        q=Query();self.files.remove(q.job_id==job_id)

# === Streamlit App ===
database = AnalyzeDatabase()
st.set_page_config(layout="wide", page_title="Recrutador", page_icon=":brain:")

# Sidebar: cadastrar vaga e curr√≠culos
st.sidebar.header("Cadastrar Vaga e Analisar Curr√≠culos")
job_name        = st.sidebar.text_input("Nome da Vaga:")
st.sidebar.markdown(f"**Atividades:**\n{activities}")
st.sidebar.markdown(f"**Pr√©-Requisitos:**\n{prerequisites}")
st.sidebar.markdown(f"**Diferenciais:**\n{differentials}")
job_description = st.sidebar.text_area("Descri√ß√£o da Vaga:")
uploaded = st.sidebar.file_uploader("Envie curr√≠culos em PDF:", type=["pdf"], accept_multiple_files=True)
if st.sidebar.button("Analisar Curr√≠culos"):
    if not job_name or not job_description or not uploaded:
        st.sidebar.error("Preencha todos os campos e envie ao menos um PDF.")
    else:
        os.makedirs("uploads", exist_ok=True)
        job_id = str(uuid.uuid4())
        database.jobs.insert({"id":job_id,"name":job_name,"description":job_description})
        for pdf in uploaded:
            rid = str(uuid.uuid4()); path=f"uploads/{rid}_{pdf.name}"
            with open(path,"wb") as f: f.write(pdf.getbuffer())
            database.files.insert({"id":rid,"job_id":job_id,"file":path})
            text="".join([p.extract_text() or "" for p in PdfReader(path).pages])
            # JSON analysis
            prompt_json=f"Analise este curr√≠culo para '{job_name}' e retorne JSON com name, education, skills, languages, score, opinion.\nCurr√≠culo:\n{text}"
            raw=client.chat.completions.create(model="gpt-4o-mini",messages=[{"role":"user","content":prompt_json}]).choices[0].message.content
            try: data=json.loads(raw)
            except: m=re.search(r"(\{.*\})",raw,re.DOTALL); data=json.loads(m.group(1)) if m else {}
            database.resums.insert({"id":rid,"job_id":job_id,"content":data.get("name"),"file":path})
            database.analysis.insert({"id":str(uuid.uuid4()),"job_id":job_id,"resum_id":rid,
                                        "name":data.get("name"),"education":data.get("education"),
                                        "skills":data.get("skills"),"languages":data.get("languages"),
                                        "score":data.get("score")})
        st.sidebar.success("An√°lises conclu√≠das.")

# Main: Ranking e detalhes em lista
st.title("Recrutador")
jobs=database.jobs.all()
sel=st.selectbox("Escolha sua vaga:",[j['name'] for j in jobs])
if sel:
    job=database.get_job_by_name(sel)
    analyses=database.get_analysis_by_job_id(job['id'])
    if analyses:
        import pandas as pd
        df=pd.DataFrame(analyses).sort_values('score',ascending=False).reset_index(drop=True)
        df['Ranking']=df.index+1
        df.rename(columns={'name':'Nome','education':'Educa√ß√£o','skills':'Habilidades','languages':'Idiomas','score':'Score'},inplace=True)
        st.subheader("üèÜ Ranking de Candidatos")
        st.dataframe(df[['Ranking','Nome','Score']])
        st.subheader("Detalhes dos Candidatos")
        for row in df.itertuples(index=False):
            st.markdown(f"---\n#### {row.Nome} (Ranking: {row.Ranking}, Score: {row.Score})")
            resum=database.get_resum_by_id(row.resum_id)
            text="".join([p.extract_text() or "" for p in PdfReader(resum['file']).pages])
            st.markdown(resume_cv(text))
            st.markdown(generate_opinion(text,job_description))
            with open(resum['file'],'rb') as f:
                st.download_button(f"Download {row.Nome}",f,file_name=os.path.basename(resum['file']),mime="application/pdf")
        if st.button('Limpar An√°lise'):
            for r in database.get_resums_by_job_id(job['id']): os.remove(r['file'])
            database.delete_all_resums_by_job_id(job['id'])
            database.delete_all_analysis_by_job_id(job['id'])
            database.delete_all_files_by_job_id(job['id'])
            st.experimental_rerun()