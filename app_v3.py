import os
import uuid
import json
import re
import streamlit as st
from dotenv import load_dotenv
from tinydb import TinyDB, Query
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
from PyPDF2 import PdfReader
from openai import OpenAI

# === Carrega vari√°veis de ambiente ===
dotenv_path = os.path.join(os.path.dirname(__file__), ".env")
load_dotenv(dotenv_path)
api_key = os.getenv("OPENAI_API_KEY", "").strip()
if not api_key:
    st.error("Chave OPENAI_API_KEY n√£o encontrada. Verifique .env sem espa√ßos extras nem aspas.")
    st.stop()
client = OpenAI(api_key=api_key)

# === Helper para converter c√©lulas em strings ===
def stringify_cell(x):
    if isinstance(x, (list, tuple)):
        return ", ".join(str(item) for item in x)
    if isinstance(x, dict):
        return json.dumps(x)
    return str(x) if x is not None else ""

# === Classe de Banco de Dados ===
class AnalyzeDatabase(TinyDB):
    def __init__(self, file_path='db.json') -> None:
        super().__init__(file_path)
        self.jobs     = self.table('jobs')
        self.resums   = self.table('resums')
        self.analysis = self.table('analysis')
        self.files    = self.table('files')

    def get_job_by_name(self, name):
        q = Query()
        res = self.jobs.search(q.name == name)
        return res[0] if res else None

    def get_resum_by_id(self, id):
        q = Query()
        res = self.resums.search(q.id == id)
        return res[0] if res else None

    def get_analysis_by_job_id(self, job_id):
        q = Query()
        return self.analysis.search(q.job_id == job_id)

    def get_resums_by_job_id(self, job_id):
        q = Query()
        return self.resums.search(q.job_id == job_id)

    def delete_all_resums_by_job_id(self, job_id):
        q = Query()
        self.resums.remove(q.job_id == job_id)

    def delete_all_analysis_by_job_id(self, job_id):
        q = Query()
        self.analysis.remove(q.job_id == job_id)

    def delete_all_files_by_job_id(self, job_id):
        q = Query()
        self.files.remove(q.job_id == job_id)

# Inicializa banco e Streamlit
database = AnalyzeDatabase()
st.set_page_config(layout="wide", page_title="Recrutador", page_icon=":brain:")

# Templates de descri√ß√£o de vagas
activities = """
Participar da defini√ß√£o das tecnologias utilizadas no desenvolvimento dos sistemas
Codificar sistemas e aplica√ß√µes de acordo com padr√µes e metodologias estabelecidas
Estimar prazos para realiza√ß√£o das tarefas com base em documentos de requisitos
Desenvolver sistemas aplicando as tecnologias definidas pelo time
Comentar e documentar o c√≥digo desenvolvido
Criar e aplicar testes unit√°rios
Realizar manuten√ß√µes corretivas em sistemas e aplica√ß√µes (corre√ß√£o de bugs)
"""
prerequisites = """
Conhecimento em Python e Java
Experi√™ncia com frameworks como Django
Familiaridade com Docker, Git e bancos de dados Postgres
Conhecimento sobre metodologias √°geis, especialmente Scrum
Disponibilidade para trabalho presencial em Florian√≥polis, SC
"""
differentials = """
Conhecimento em Flutter
Experi√™ncia com Django Rest Framework ou Flask
Viv√™ncia com pipelines de CI/CD
Familiaridade com arquitetura em nuvem (AWS API Gateway, Lambda Functions)
Experi√™ncia com microservi√ßos, RabbitMQ, Event Source e bancos NoSQL como MongoDB
"""

# Sidebar: cadastro de vaga e upload de curr√≠culos
st.sidebar.header("Cadastrar Vaga e Analisar Curr√≠culos")
job_name        = st.sidebar.text_input("Nome da Vaga:")
st.sidebar.markdown("**Atividades:**\n" + activities)
st.sidebar.markdown("**Pr√©-Requisitos:**\n" + prerequisites)
st.sidebar.markdown("**Diferenciais:**\n" + differentials)
job_description = st.sidebar.text_area("Descri√ß√£o da Vaga (respeitando a estrutura acima):")
uploaded_pdfs   = st.sidebar.file_uploader("Envie curr√≠culos em PDF:", type=["pdf"], accept_multiple_files=True)

if st.sidebar.button("Analisar Curr√≠culos"):
    if not job_name or not job_description or not uploaded_pdfs:
        st.sidebar.error("Preencha nome, descri√ß√£o e envie ao menos um PDF.")
    else:
        os.makedirs("uploads", exist_ok=True)
        job_id = str(uuid.uuid4())
        database.jobs.insert({"id": job_id, "name": job_name, "description": job_description})
        for pdf_file in uploaded_pdfs:
            resum_id = str(uuid.uuid4())
            path = os.path.join("uploads", f"{resum_id}_{pdf_file.name}")
            with open(path, "wb") as f:
                f.write(pdf_file.getbuffer())
            database.files.insert({"id": resum_id, "job_id": job_id, "file": path})

            # Extrai texto do PDF
            text = "".join([p.extract_text() or "" for p in PdfReader(path).pages])

            # Prompt para IA
            prompt = (
                f"Analise este curr√≠culo para a vaga '{job_name}'. Retorne JSON com: name, education, skills (lista), languages (lista), score (0-100), opinion.\n\nCurr√≠culo:\n" + text
            )

            # Chamada √† API OpenAI
            raw = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um sistema de an√°lise de curr√≠culos para recrutamento."},
                    {"role": "user",   "content": prompt}
                ]
            ).choices[0].message.content

            # Parse JSON com fallback
            try:
                res = json.loads(raw)
            except json.JSONDecodeError:
                m = re.search(r"(\{.*\})", raw, re.DOTALL)
                res = json.loads(m.group(1)) if m else {}

            # Persiste dados
            database.resums.insert({
                "id": resum_id,
                "job_id": job_id,
                "content": res.get("name"),
                "opinion": res.get("opinion"),
                "file": path
            })
            database.analysis.insert({
                "id":       str(uuid.uuid4()),
                "job_id":   job_id,
                "resum_id": resum_id,
                "name":     res.get("name"),
                "education":res.get("education"),
                "skills":   res.get("skills"),
                "languages":res.get("languages"),
                "score":    res.get("score")
            })
        st.sidebar.success("An√°lise conclu√≠da e salva no TinyDB.")

# Main: ranking e visualiza√ß√£o de resultados
st.title("Recrutador")
jobs   = database.jobs.all()
option = st.selectbox("Escolha sua vaga:", [j['name'] for j in jobs])
if option:
    job      = database.get_job_by_name(option)
    analyses = database.get_analysis_by_job_id(job['id'])
    if analyses:
        import pandas as pd
        df = pd.DataFrame(analyses)

        # Ranking
        df = df.sort_values('score', ascending=False).reset_index(drop=True)
        df['Ranking'] = df.index + 1

        # Renomeia colunas
        df = df.rename(columns={
            'name':      'Nome',
            'education': 'Educa√ß√£o',
            'skills':    'Habilidades',
            'languages': 'Idiomas',
            'score':     'Score'
        })

        # Tabela de ranking
        st.subheader("üèÜ Ranking de Candidatos")
        st.table(df[['Ranking','Nome','Score']])

        # Gr√°fico de scores
        st.subheader("Gr√°fico de Scores")
        st.bar_chart(df, x='Nome', y='Score', horizontal=True)

        # Detalhes interativos com AgGrid
        st.subheader("Detalhes dos Candidatos")
        df_details = df[['resum_id','Nome','Educa√ß√£o','Habilidades','Idiomas','Score']].copy()
        for col in ['Educa√ß√£o','Habilidades','Idiomas']:
            df_details[col] = df_details[col].apply(stringify_cell)

        gb = GridOptionsBuilder.from_dataframe(df_details)
        gb.configure_column('resum_id', hide=True)
        gb.configure_pagination(paginationAutoPageSize=True)
        gb.configure_column('Score', sort='desc')
        gb.configure_selection(selection_mode='multiple', use_checkbox=True)
        grid_opts = gb.build()

        grid_resp = AgGrid(df_details, gridOptions=grid_opts,
                            enable_enterprise_modules=True,
                            update_mode=GridUpdateMode.SELECTION_CHANGED,
                            theme='streamlit')
        selected = grid_resp.get('selected_rows') or []

        if len(selected) > 0:
            cols = st.columns(len(selected))
            for i, row in enumerate(selected):
                resum_id = row.get('resum_id')
                data = database.get_resum_by_id(resum_id)
                with cols[i]:
                    st.markdown(f"### {data['content']}")
                    st.markdown(data['opinion'])
                    with open(data['file'],'rb') as f:
                        st.download_button(label=f"Download {data['content']}",
                                            data=f,
                                            file_name=os.path.basename(data['file']),
                                            mime='application/pdf')

                # Limpar an√°lises
        if st.button('Limpar An√°lise'):
            for r in database.get_resums_by_job_id(job['id']):
                if os.path.isfile(r['file']): os.remove(r['file'])
            database.delete_all_resums_by_job_id(job['id'])
            database.delete_all_analysis_by_job_id(job['id'])
            database.delete_all_files_by_job_id(job['id'])
            # Tentativa de recarregar a p√°gina
            try:
                st.experimental_rerun()
            except AttributeError:
                st.success("An√°lises limpas. Por favor, recarregue a p√°gina para atualizar os dados.")
